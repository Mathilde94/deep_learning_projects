{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from data.text_load import text_build_for_lstm\n",
    "from models.models import LSTM\n",
    "from classifier.models import LSTMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified text8.zip\n",
      "('vocabulary_size', 27)\n",
      "('num_unrollings', 10)\n",
      "('name', 'lstm')\n",
      "('num_nodes', 64)\n",
      "Average loss at step 0: 3.293061 learning rate: 10.000000\n",
      "Minibatch perplexity: 26.93\n",
      "================================================================================\n",
      "nans  bcipu ied evuyogivsdafszhhjywf   gkaahebqjsy  cjn eitj dm u emee hnnas hin\n",
      "jgo d  zirvxon qtetqa en gecjdax  iad tdldf gckgv xbnrxnwllqaneex hp htu  nnibta\n",
      "edcpyweesanujlnhio tk lytptezj  hjihirtr ninmiarfbd ujmdsb zupe c pu oatr em kzn\n",
      "qsce hethdeinshzkwol f ienwc yrgyut rstapiijamz   uceudvq efk cctzjasclvioiajens\n",
      "fn ahsto  iilinqa ptf cv e usoegcnsei htbovfclz n y abet oyki lt egqv unzp  a ij\n",
      "================================================================================\n",
      "Validation set perplexity: 19.94\n",
      "Average loss at step 100: 2.588724 learning rate: 10.000000\n",
      "Minibatch perplexity: 10.20\n",
      "Validation set perplexity: 10.14\n",
      "Average loss at step 200: 2.245340 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.75\n",
      "Validation set perplexity: 8.47\n",
      "Average loss at step 300: 2.095202 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.65\n",
      "Validation set perplexity: 7.72\n",
      "Average loss at step 400: 1.995013 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.33\n",
      "Validation set perplexity: 7.52\n",
      "Average loss at step 500: 1.934346 learning rate: 10.000000\n",
      "Minibatch perplexity: 7.37\n",
      "Validation set perplexity: 7.04\n",
      "Average loss at step 600: 1.905865 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.58\n",
      "Validation set perplexity: 6.95\n",
      "Average loss at step 700: 1.854454 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.53\n",
      "Validation set perplexity: 6.60\n",
      "Average loss at step 800: 1.820240 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.69\n",
      "Validation set perplexity: 6.51\n",
      "Average loss at step 900: 1.825701 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.07\n",
      "Validation set perplexity: 6.32\n",
      "Average loss at step 1000: 1.826277 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.42\n",
      "================================================================================\n",
      "er of thearre amert be p of the sers pirks phiszer as citmas grom two fout the f\n",
      "h poport the scomed of haut the kall littrussic mi of and grasevil strictional i\n",
      "zem two zero zero aboro two mary be useve hapsan agen the his has the as reputad\n",
      "had on eiclon the scutition refersic ryfing the two de aling be fing bokely it d\n",
      "ve be shie he ang carecemply us who nindol teas xubin of the usey ap rout from t\n",
      "================================================================================\n",
      "Validation set perplexity: 6.24\n",
      "Average loss at step 1100: 1.775073 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.73\n",
      "Validation set perplexity: 5.83\n",
      "Average loss at step 1200: 1.749382 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.04\n",
      "Validation set perplexity: 5.75\n",
      "Average loss at step 1300: 1.730682 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.19\n",
      "Validation set perplexity: 5.67\n",
      "Average loss at step 1400: 1.739858 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.10\n",
      "Validation set perplexity: 5.59\n",
      "Average loss at step 1500: 1.735376 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.59\n",
      "Validation set perplexity: 5.52\n",
      "Average loss at step 1600: 1.742732 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.92\n",
      "Validation set perplexity: 5.34\n",
      "Average loss at step 1700: 1.710024 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.33\n",
      "Validation set perplexity: 5.36\n",
      "Average loss at step 1800: 1.675005 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.66\n",
      "Validation set perplexity: 5.32\n",
      "Average loss at step 1900: 1.644148 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.17\n",
      "Validation set perplexity: 5.29\n",
      "Average loss at step 2000: 1.692298 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.09\n",
      "================================================================================\n",
      "jured ri moxecrians in anowork notefion mashine lefker of lower s madry x is mac\n",
      "x algembert norea locallian of gamasitian s betabanter jewvil propersers inso ba\n",
      "with parecting to a mexing nomber the prece deen lish it sitrates were the ector\n",
      "d jublets one years coussalded from filodory not gormun terge sects not wowen bo\n",
      "art mohish propertsion nomentifived tainete romating hown s in one nine nine nin\n",
      "================================================================================\n",
      "Validation set perplexity: 5.28\n",
      "Average loss at step 2100: 1.689637 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.23\n",
      "Validation set perplexity: 5.06\n",
      "Average loss at step 2200: 1.679083 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.91\n",
      "Validation set perplexity: 5.31\n",
      "Average loss at step 2300: 1.643970 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.35\n",
      "Validation set perplexity: 5.06\n",
      "Average loss at step 2400: 1.659106 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.49\n",
      "Validation set perplexity: 4.94\n",
      "Average loss at step 2500: 1.680671 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.34\n",
      "Validation set perplexity: 4.79\n",
      "Average loss at step 2600: 1.654670 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.31\n",
      "Validation set perplexity: 4.73\n",
      "Average loss at step 2700: 1.662081 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.48\n",
      "Validation set perplexity: 4.79\n",
      "Average loss at step 2800: 1.649570 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.88\n",
      "Validation set perplexity: 4.69\n",
      "Average loss at step 2900: 1.650361 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.91\n",
      "Validation set perplexity: 4.75\n",
      "Average loss at step 3000: 1.653171 learning rate: 10.000000\n",
      "Minibatch perplexity: 6.01\n",
      "================================================================================\n",
      "nogy aineto cilegation is was tedrests ancimity and thoss and come to a unit oba\n",
      " gestant he jakuble varn daybarmance of come been trans as pottry in other in to\n",
      "line he somelite epoved the such hoxbie as commutical after and antions and its \n",
      "grawsiving christmounters several the closul as the a members apears low starme \n",
      "phurationtedantane put dandemv six seven one anlises the gaiens co plased one ni\n",
      "================================================================================\n",
      "Validation set perplexity: 4.68\n",
      "Average loss at step 3100: 1.624355 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.69\n",
      "Validation set perplexity: 4.68\n",
      "Average loss at step 3200: 1.646681 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.34\n",
      "Validation set perplexity: 4.80\n",
      "Average loss at step 3300: 1.636066 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.94\n",
      "Validation set perplexity: 4.59\n",
      "Average loss at step 3400: 1.671264 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.93\n",
      "Validation set perplexity: 4.62\n",
      "Average loss at step 3500: 1.656284 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.39\n",
      "Validation set perplexity: 4.74\n",
      "Average loss at step 3600: 1.672452 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.80\n",
      "Validation set perplexity: 4.71\n",
      "Average loss at step 3700: 1.645957 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.68\n",
      "Validation set perplexity: 4.63\n",
      "Average loss at step 3800: 1.644199 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.05\n",
      "Validation set perplexity: 4.73\n",
      "Average loss at step 3900: 1.641455 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.56\n",
      "Validation set perplexity: 4.65\n",
      "Average loss at step 4000: 1.652172 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.92\n",
      "================================================================================\n",
      "a eccept s the centuryle beto the the the viewing and when ed the jampouraza ind\n",
      "hame of move and sestem can etgrab ungered field the pujiumholobreted madapiropp\n",
      "kel and linum writer floy ivelyra b ised an erfoscos alner undever elgeroms byri\n",
      "s to one five nine two zero eight in obthary during meceses beckuely initially e\n",
      "press poprenta its considertal credioks records as clort areht of a struch pieda\n",
      "================================================================================\n",
      "Validation set perplexity: 4.71\n",
      "Average loss at step 4100: 1.631945 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.30\n",
      "Validation set perplexity: 4.79\n",
      "Average loss at step 4200: 1.633990 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.35\n",
      "Validation set perplexity: 4.66\n",
      "Average loss at step 4300: 1.613708 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.25\n",
      "Validation set perplexity: 4.52\n",
      "Average loss at step 4400: 1.615187 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.83\n",
      "Validation set perplexity: 4.55\n",
      "Average loss at step 4500: 1.616260 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.67\n",
      "Validation set perplexity: 4.45\n",
      "Average loss at step 4600: 1.613978 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.14\n",
      "Validation set perplexity: 4.62\n",
      "Average loss at step 4700: 1.625153 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.69\n",
      "Validation set perplexity: 4.60\n",
      "Average loss at step 4800: 1.635275 learning rate: 10.000000\n",
      "Minibatch perplexity: 5.23\n",
      "Validation set perplexity: 4.70\n",
      "Average loss at step 4900: 1.630453 learning rate: 10.000000\n",
      "Minibatch perplexity: 4.56\n",
      "Validation set perplexity: 4.67\n",
      "Average loss at step 5000: 1.612366 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.98\n",
      "================================================================================\n",
      "thic looger the prowent imbour sin smith nazarrate travatina and incluse allow v\n",
      "foy ross in two zero zero zero six three populan simmenez of and or boushastians\n",
      "coustian avestime two zero fort from histogestne and with the ballin commigners \n",
      "han and will it and resluind s guduer desporten but four carrve he in to by proy\n",
      "kaca is michish societ bytect became before over southeleste sointred me word co\n",
      "================================================================================\n",
      "Validation set perplexity: 4.70\n",
      "Average loss at step 5100: 1.603996 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.13\n",
      "Validation set perplexity: 4.50\n",
      "Average loss at step 5200: 1.597111 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.08\n",
      "Validation set perplexity: 4.44\n",
      "Average loss at step 5300: 1.577204 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.44\n",
      "Validation set perplexity: 4.44\n",
      "Average loss at step 5400: 1.577234 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.94\n",
      "Validation set perplexity: 4.39\n",
      "Average loss at step 5500: 1.571089 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.29\n",
      "Validation set perplexity: 4.37\n",
      "Average loss at step 5600: 1.578329 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.34\n",
      "Validation set perplexity: 4.37\n",
      "Average loss at step 5700: 1.570393 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.42\n",
      "Validation set perplexity: 4.36\n",
      "Average loss at step 5800: 1.581158 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.38\n",
      "Validation set perplexity: 4.38\n",
      "Average loss at step 5900: 1.576047 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.83\n",
      "Validation set perplexity: 4.37\n",
      "Average loss at step 6000: 1.553538 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.44\n",
      "================================================================================\n",
      "pain edic selven compointhman drustes live plrmander findon discount frost that \n",
      "comer then by junght first four seven three two zero zero sarvazianh place earmi\n",
      "el eahnar even r mike penalar purizative become only as stanted in one nine the \n",
      "zersong r one sing a seven two zero four nonee one nine three two if dolang are \n",
      "ration shmepheses adbian of icalite hest y basix in the throeeraty persience to \n",
      "================================================================================\n",
      "Validation set perplexity: 4.35\n",
      "Average loss at step 6100: 1.569784 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.97\n",
      "Validation set perplexity: 4.33\n",
      "Average loss at step 6200: 1.538501 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.18\n",
      "Validation set perplexity: 4.33\n",
      "Average loss at step 6300: 1.544447 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.17\n",
      "Validation set perplexity: 4.33\n",
      "Average loss at step 6400: 1.539135 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.75\n",
      "Validation set perplexity: 4.34\n",
      "Average loss at step 6500: 1.556161 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.90\n",
      "Validation set perplexity: 4.34\n",
      "Average loss at step 6600: 1.597726 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.00\n",
      "Validation set perplexity: 4.34\n",
      "Average loss at step 6700: 1.579529 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.58\n",
      "Validation set perplexity: 4.33\n",
      "Average loss at step 6800: 1.604948 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.18\n",
      "Validation set perplexity: 4.32\n",
      "Average loss at step 6900: 1.584750 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.86\n",
      "Validation set perplexity: 4.35\n",
      "Average loss at step 7000: 1.577223 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.89\n",
      "================================================================================\n",
      "ond proquetment airiols in the versient seven defentive aradiate penal forth ary\n",
      "hers bettereich political japan commertaphy they progrophects than four smains a\n",
      "jeps man one nine nine nine tw foogle between her has so the cluckws in one nine\n",
      "on mami borker bolksa most his yeet one nine seven nonneux of keyding that mains\n",
      "es of the suakshy pridfer to weig y laips to the store impoir were more involves\n",
      "================================================================================\n",
      "Validation set perplexity: 4.33\n",
      "Average loss at step 7100: 1.574118 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.68\n",
      "Validation set perplexity: 4.31\n",
      "Average loss at step 7200: 1.572567 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.47\n",
      "Validation set perplexity: 4.31\n",
      "Average loss at step 7300: 1.570819 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.78\n",
      "Validation set perplexity: 4.30\n",
      "Average loss at step 7400: 1.584071 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.24\n",
      "Validation set perplexity: 4.35\n",
      "Average loss at step 7500: 1.591762 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.45\n",
      "Validation set perplexity: 4.32\n",
      "Average loss at step 7600: 1.561520 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.05\n",
      "Validation set perplexity: 4.32\n",
      "Average loss at step 7700: 1.549479 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.71\n",
      "Validation set perplexity: 4.31\n",
      "Average loss at step 7800: 1.577885 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.83\n",
      "Validation set perplexity: 4.34\n",
      "Average loss at step 7900: 1.587878 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.06\n",
      "Validation set perplexity: 4.32\n",
      "Average loss at step 8000: 1.620310 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.44\n",
      "================================================================================\n",
      "is docker including alfames roses ould to and stating is while on joll the ama t\n",
      " top is finally beroce contract wys both a septess was about orc pafer stitt fem\n",
      "haardman sond about one nine two nine three octims gooder ween a port of fourth \n",
      "le as five paired community distirlle x of king gaugglean that is notablg leanfi\n",
      "d and totes in thet found number invuloted service seem arrian new plased junned\n",
      "================================================================================\n",
      "Validation set perplexity: 4.34\n",
      "Average loss at step 8100: 1.596605 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.20\n",
      "Validation set perplexity: 4.39\n",
      "Average loss at step 8200: 1.571582 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.82\n",
      "Validation set perplexity: 4.36\n",
      "Average loss at step 8300: 1.576488 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.62\n",
      "Validation set perplexity: 4.38\n",
      "Average loss at step 8400: 1.586906 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.13\n",
      "Validation set perplexity: 4.38\n",
      "Average loss at step 8500: 1.587109 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.72\n",
      "Validation set perplexity: 4.38\n",
      "Average loss at step 8600: 1.579922 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.93\n",
      "Validation set perplexity: 4.38\n",
      "Average loss at step 8700: 1.570577 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.52\n",
      "Validation set perplexity: 4.36\n",
      "Average loss at step 8800: 1.546240 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.77\n",
      "Validation set perplexity: 4.31\n",
      "Average loss at step 8900: 1.565349 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.42\n",
      "Validation set perplexity: 4.32\n",
      "Average loss at step 9000: 1.553307 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.81\n",
      "================================================================================\n",
      "way central face to deferences i arginulated efft reathern tllowing feacy weaked\n",
      "vents joseries and member of namelen gaceti into has this if op the acture three\n",
      "right as driesakis from the mbs to but nates appronom han which after the clos w\n",
      "ad neater htrjaring beensit of glaberly autual brandsm uninty in minically and c\n",
      "grangern scholl sandroblovian a to rutu with addht armethynman open one rallust \n",
      "================================================================================\n",
      "Validation set perplexity: 4.33\n",
      "Average loss at step 9100: 1.569647 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.56\n",
      "Validation set perplexity: 4.32\n",
      "Average loss at step 9200: 1.598527 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.97\n",
      "Validation set perplexity: 4.32\n",
      "Average loss at step 9300: 1.606429 learning rate: 1.000000\n",
      "Minibatch perplexity: 6.02\n",
      "Validation set perplexity: 4.31\n",
      "Average loss at step 9400: 1.594234 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.42\n",
      "Validation set perplexity: 4.31\n",
      "Average loss at step 9500: 1.601127 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.45\n",
      "Validation set perplexity: 4.31\n",
      "Average loss at step 9600: 1.583605 learning rate: 1.000000\n",
      "Minibatch perplexity: 4.75\n",
      "Validation set perplexity: 4.30\n",
      "Average loss at step 9700: 1.601815 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.23\n",
      "Validation set perplexity: 4.30\n",
      "Average loss at step 9800: 1.596931 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.52\n",
      "Validation set perplexity: 4.31\n",
      "Average loss at step 9900: 1.598562 learning rate: 1.000000\n",
      "Minibatch perplexity: 5.12\n",
      "Validation set perplexity: 4.32\n",
      "Average loss at step 10000: 1.615285 learning rate: 0.100000\n",
      "Minibatch perplexity: 5.26\n",
      "================================================================================\n",
      "quiblish was such throught overime liminion of that is native reallys has and th\n",
      "our period a by where theory consignonica ruley were jomans inside rencord sity \n",
      "w heator the a sexually tas to baidobis of the each isry probale on lestengy rox\n",
      "y stantages of an identis the compasive popperis previsivele it skanka derexting\n",
      "ly descyude an ordever frome meds arezrain is he enen heptise the machines there\n",
      "================================================================================\n",
      "Validation set perplexity: 4.31\n"
     ]
    }
   ],
   "source": [
    "train_set, valid_set = text_build_for_lstm()\n",
    "model = LSTM()\n",
    "classifier = LSTMClassifier(model)\n",
    "classifier.train(train_set, valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
